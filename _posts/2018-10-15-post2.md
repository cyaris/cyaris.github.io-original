---
layout: post
title: Insights From My Second Project at Metis
---

**Variance Inflation Factor vs Coefficient Values**
<br>
*A lesson in correlation.*

For my second project at Metis, I used linear regression to predict the prices of prescription medications. Focusing only on drugs in pill form, my model contained 1027 different drugs, and aimed to predict the price per pill for each medication. The mean price per pill for the sample of drugs in my model was $15.43, with a standard deviation of $77.25, an statistic so skewed to the right it seems to suggest that the price goes into the negatives. While 97.5% of my sample had a cost per pill of less than $100, the outliers in the dataset went as high as $993 per pill. I hoped to gain insight into the factors that determine this disparity between price, which patients seeking medical treatment are forced to accept daily.

I included 18 total features in my linear regression model. Some defined the drug's chemical properties like molecular weight chemical state, and targeted receptors, while others conveyed its degree of establishment like the number of manufacturers, patents, clinical trials and dosage forms. I also included the NADAC (National Average Drug Acquisition Cost) for each drug, provided by Medicaid.gov, which was the only feature in the same units as the dependent variable (cost per pill). After running the regression, I was excited to see a high R² score of 0.88, and began working on my presentation, confident that my model had uncovered important trends in drug pricing that I could share with my peers.

The NADAC was not surprisingly my largest correlator with the cost per pill of a prescription, since we should expect that the more a pharmacy has to pay for a particular drug, the more the patient will have to pay. As a result, I hoped for my presentation to mostly highlight the other 17 important features I'd used to predict the price per pill of prescription medications.

To give the other 17 features credibility in making this prediction on their own, I ran the regression without the NADAC and ruefully accepted the results. Without including the NADAC in the model, the R² score dropped to 0.04. I immediately reran the regression, this time only including the NADAC, hoping for a score that couldn't possibly match my initial run of 0.88. To my dismay, this simply model with just one feature, returned as 0.91. The NADAC was the reason for my model's success.

I was faced with a dilemma. With my presentation only a few hours away, I needed to make a decision: Was there anything that could be learned from the 18 features in my original model? And, more importantly, should the simplicity and accuracy of my one-feature model override the answer to that first question? To answer this question, I used VIF (Variance Inflation Factor) on my original model to check for how much of the variance in my model was explained by NADAC compared to my other features. I hoped this calculation would allow me to conclude whether the other 17 features had helped in generating the 0.88 R² score.

Again, my results surprised me. Though NADAC had the largest coefficient magnitude for all features in my model at 59.27, second to a feature at -3.07, it ranked 14 out of 18 for VIF. These results suggest that even though my model without NADAC had a poor accuracy score, the other 17 features are still explaining a lot of the variance in my dataset.










